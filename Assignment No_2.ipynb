{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69417bf8",
   "metadata": {},
   "source": [
    "Q.1) Describe the structure of an artificial neuron. How is it similar to a biological neuron? What are its main components?\n",
    "\n",
    "  :- An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human         body's biological neural network, have a layered architecture and each network node (connection point) has the capability       to process input and forward output to other nodes in the network. Biological neural networks process information in           parallel; this is also true of artificial neural networks. Learning in biological neural networks is through past               experiences which improve their performance level; this is also true of artificial neural networks. The biological neuron       contains main components like cell body (also called Soma), the dendrites, and the axon.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ba05f",
   "metadata": {},
   "source": [
    "Q.2) What are the different types of activation functions popularly used? Explain each of them.\n",
    "\n",
    "  :- There are several types of activation function used.\n",
    "i)Step Function:\n",
    "Step Function is one of the simplest kind of activation functions. In this, we consider a threshold value and if the value of net input say y is greater than the threshold then the neuron is activated.\n",
    "Mathematically,\n",
    "f(x) = 1, if x>=0\n",
    "f(x) = 0, if x<0\n",
    "\n",
    "ii)Sigmoid Function:\n",
    "Sigmoid function is a widely used activation function. It is defined as:\n",
    "This is a smooth function and is continuously differentiable. The biggest advantage that it has over step and linear function is that it is non-linear. This is an incredibly cool feature of the sigmoid function. This essentially means that when I have multiple neurons having sigmoid function as their activation function – the output is non-linear as well. The function ranges from 0-1 having an S shape. It mathematically defined as,\n",
    "s(x) = 1/(1 + e−x)\n",
    "\n",
    "iii)ReLU\n",
    "The ReLU function is the Rectified linear unit. It is the most widely used activation function. It is defined as:\n",
    "The main advantage of using the ReLU function over other activation functions is that it does not activate all the neurons at the same time. What does this mean ? If you look at the ReLU function if the input is negative it will convert it to zero and the neuron does not get activated.\n",
    "Mathematically it is, \n",
    "f(x) = max(0,x)\n",
    "\n",
    "iv)Leaky ReLU:\n",
    "Leaky ReLU function is nothing but an improved version of the ReLU function.Instead of defining the Relu function as 0 for x less than 0, we define it as a small linear component of x. It can be defined as:\n",
    "f(x) = ax, x<0\n",
    "f(x) = x, otherwise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90ec9c",
   "metadata": {},
   "source": [
    "Q.3) Explain, in details, Rosenblatt’s perceptron model. How can a set of data be classified using a simple perceptron?\n",
    "\n",
    "  :- Artificial Neural Networks (ANN) are machine learning models that have been inspired by the brain functioning. Through my next posts I will try to introduce artificial neural networks in a simple high level way, highlighting its capabilities but also showing its limitations. In this first post, I will introduce the simplest neural network, the Rosenblatt Perceptron, a neural network compound of a single artificial neuron. This artificial neuron model is the basis of today’s complex neural networks and was until the mid-eighties state of the art in ANN.\n",
    "Rosenblatt perceptron is a binary single neuron model. The inputs integration is implemented through the addition of the weighted inputs that have fixed weights obtained during the training stage. If the result of this addition is larger than a given threshold θ the neuron fires. When the neuron fires its output is set to 1, otherwise it’s set to 0. This model implements the functioning of a single neuron that can solve linear classification problems through very simple learning algorithms. Rosenblatt Perceptrons are considered as the first generation of neural networks (the network is only compound of one neuron). This simple single neuron model has the main limitation of not being able to solve non-linear separable problems.\n",
    "\n",
    "Use a simple perceptron with weights w 0 , w 1 , and w 2  as −1, 2, and 1, respectively, to classify data points (3, 4); (5, 2); (1, −3); (−8, −3); (−3, 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2d4ad",
   "metadata": {},
   "source": [
    "Q.4) Explain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR problem.\n",
    "\n",
    "  :- The XOR problem with neural networks can be solved by using Multi-Layer Perceptron’s or a neural network architecture with an input layer, hidden layer, and output layer. So during the forward propagation through the neural networks, the weights get updated to the corresponding layers and the XOR logic gets executed.\n",
    "The XOr problem\n",
    "The XOr problem is that we need to build a Neural Network (a perceptron in our case) to produce the truth table related to the XOr logical operator. This is a binary classification problem. Hence, supervised learning is a better way to solve it. In this case, we will be using perceptrons. Uni layered perceptrons can only work with linearly separable data. But in the following diagram drawn in accordance with the truth table of the XOr loical operator, we can see that the data is NOT linearly separable.\n",
    "To solve this problem, we add an extra layer to our vanilla perceptron, i.e., we create a Multi Layered Perceptron (or MLP). We call this extra layer as the Hidden layer. To build a perceptron, we first need to understand that the XOr gate can be written as a combination of AND gates, NOT gates and OR gates in the following way:\n",
    "a XOr b = (a AND NOT b)OR(bAND NOTa)\n",
    "\n",
    "Here, we need to observe that our inputs are 0s and 1s. To make it a XOr gate, we will make the h1 node to perform the (x2 AND NOT x1) operation, the h2 node to perform (x1 AND NOT x2) operation and the y node to perform (h1 OR h2) operation. The NOT gate can be produced for an input a by writing (1-a), the AND gate can be produced for inputs a and b by writing (a.b) and the OR gate can be produced for inputs a and b by writing (a+b). Also, we'll use the sigmoid function as our activation function σ, i.e., σ(x) = 1/(1+e^(-x)) and the threshold for classification would be 0.5, i.e., any x with σ(x)>0.5 will be classified as 1 and others will be classified as 0. Now, since we have all the information, we can go on to define h1, h2 and y. Using the formulae for AND, NOT and OR gates, we get:\n",
    "1.\th1 = σ((1-x1) + x2) = σ((-1)x1 + x2 + 1)\n",
    "2.\th2 = σ(x1 + (1-x2)) = σ(x1 + (-1)x2 + 1)\n",
    "3.\ty = σ(h1 + h2) = σ(h1 + h2 + 0)\n",
    "Hence, we have built a multi layered perceptron with the following weights and it predicts the output of a XOr logical operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db04ef8",
   "metadata": {},
   "source": [
    "Q.5) 1) What is artificial neural network (ANN)? Explain some of the salient highlights in the different architectural options for ANN.\n",
    "\n",
    ":- The term \"Artificial Neural Network\" is derived from Biological neural networks that develop the structure of a human brain. Similar to the human brain that has neurons interconnected to one another, artificial neural networks also have neurons that are interconnected to one another in various layers of the networks. These neurons are known as nodes.\n",
    "Different architectural option for ANN are:-\n",
    "Feedforward Neural Networks: This is the simplest type of ANN architecture, where the information flows in one direction from input to output. The layers are fully connected, meaning each neuron in a layer is connected to all the neurons in the next layer.\n",
    "Recurrent Neural Networks (RNNs): These networks have a “memory” component, where information can flow in cycles through the network. This allows the network to process sequences of data, such as time series or speech.\n",
    "Convolutional Neural Networks (CNNs): These networks are designed to process data with a grid-like topology, such as images. The layers consist of convolutional layers, which learn to detect specific features in the data, and pooling layers, which reduce the spatial dimensions of the data.\n",
    "Autoencoders: These are neural networks that are used for unsupervised learning. They consist of an encoder that maps the input data to a lower-dimensional representation and a decoder that maps the representation back to the original data.\n",
    "Generative Adversarial Networks (GANs): These are neural networks that are used for generative modeling. They consist of two parts: a generator that learns to generate new data samples, and a discriminator that learns to distinguish between real and generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1ac4a",
   "metadata": {},
   "source": [
    "Q.6) Explain the learning process of an ANN. Explain, with example\n",
    "\n",
    "  :- Learning, in artificial neural network, is the method of modifying the weights of connections between the neurons of a specified network. Learning in ANN can be classified into three categories namely supervised learning, unsupervised learning, and reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37b3d2",
   "metadata": {},
   "source": [
    "Q.7) Explain, in details, the backpropagation algorithm. What are the limitations of this algorithm?\n",
    "\n",
    "  :- Backpropagation, or backward propagation of errors, is an algorithm that is designed to test for errors working back from output nodes to input nodes. It is an important mathematical tool for improving the accuracy of predictions in data mining and machine learning.\n",
    "Limitations – \n",
    "•\tIt is sensitive to noisy data and irregularities. Noisy data can lead to inaccurate results.\n",
    "•\tPerformance is highly dependent on input data.\n",
    "•\tSpending too much time training.\n",
    "•\tThe matrix-based approach is preferred over a mini-batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb5860",
   "metadata": {},
   "source": [
    "Q.8) What are the steps in the backpropagation algorithm? Why a multi-layer neural network is required?\n",
    "\n",
    "  :-Step – 1: Forward Propagation\n",
    "   Step – 2: Backward Propagation \n",
    "   Step – 3: Putting all the values together and calculating the updated weight value. So basic purpose of multi layer neural network is to control model complexity or capacity. The model with less complexity cannot understand training dataset properly means it will underfit (Dumb model) and we get higher error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a90fe4",
   "metadata": {},
   "source": [
    "Q.9) Write short notes on:\n",
    "\n",
    "Artificial neuron:-\n",
    "An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human body's biological neural network, have a layered architecture and each network node (connection point) has the capability to process input and forward output to other nodes in the network. Artificial neurons are modelled after the hierarchical arrangement of neurons in biological sensory systems. In the visual system, for example, light input passes through neurons in successive layers of the retina before being passed to neurons in the thalamus of the brain and then on to neurons in the brain's visual cortex. As the neurons pass signals through an increasing number of layers, the brain progressively extracts more information until it is confident it can identify what the person is seeing.\n",
    "\n",
    "Multi-layer perceptron: -\n",
    "Multi-layer perception is also known as MLP. It is fully connected dense layers, which transform any input dimension to the desired dimension. A multi-layer perception is a neural network that has multiple layers. To create a neural network, we combine neurons together so that the outputs of some neurons are inputs of other neurons. A multi-layer perceptron has one input layer and for each input, there is one neuron (or node), it has one output layer with a single node for each output and it can have any number of hidden layers and each hidden layer can have any number of nodes.\n",
    "\n",
    "Deep learning: -\n",
    "Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain—albeit far from matching its ability—allowing it to “learn” from large amounts of data. Deep learning drives many artificial intelligence (AI) applications and services that improve automation, performing analytical and physical tasks without human intervention. \n",
    "\n",
    "Learning rate: -\n",
    "The learning rate, denoted by the symbol α, is a hyper-parameter used to govern the pace at which an algorithm updates or learns the values of a parameter estimate. In other words, the learning rate regulates the weights of our neural network concerning the loss gradient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
