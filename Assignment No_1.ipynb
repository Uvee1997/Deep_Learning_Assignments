{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f116a60",
   "metadata": {},
   "source": [
    "Q.1) What is the function of a summation junction of a neuron? What is threshold activation function?\n",
    "\n",
    "  :- Summing junction adds all the products of the synapses and parameters. A threshold value determines whether a neuron            should be activated or not activated in a binary step activation function. The activation function compares the input          value to a threshold value, if the input value is greater than threshold value, the neuron get's activated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5aa73",
   "metadata": {},
   "source": [
    "Q.2) What is a step function? What is the difference of step function with threshold function?\n",
    "\n",
    "  :- It is also called as staircase function. It defined as piecewise constant function, that only finite number of pieces. A        step function is a function like that used by the original Perceptron. The output is a certain value, A1, if the input sum      is above a certain threshold and A0 if the input sum is below a certain threshold. The values used by the Perceptron were      A1 = 1 and A0 = 0. A function that takes the value 1 if a specified function of the arguments exceeds a given threshold        and 0 otherwise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b50211",
   "metadata": {},
   "source": [
    "Q.3) Explain the McCulloch–Pitts model of neuron.\n",
    "\n",
    "  :- The McCulloch Pitt's Model of Neuron is the earliest logical simulation of a biological neuron, developed by Warren            McCulloch and Warren Pitts in 1943 and hence, the name McCulloch Pitt’s model.\n",
    "  \n",
    "     Model of Architecture - The motivation behind the McCulloh Pitt’s Model is a biological neuron. A biological neuron takes      an input signal from the dendrites and after processing it passes onto other connected neurons as the output if the signal      is received positively, through axons and synapses. This is the basic working of a biological neuron which is interpreted      and mimicked using the McCulloh Pitt’s Model.\n",
    "     McCulloch Pitt’s model of neuron is a fairly simple model which consists of some (n) binary inputs with some weight            associated with each one of them. An input is known as ‘inhibitory input’ if the weight associated with the input is of        negative magnitude and is known as ‘excitatory input’ if the weight associated with the input is of positive magnitude. As      the inputs are binary, they can take either of the 2 values, 0 or 1. Then we have a summation junction that aggregates all      the weighted inputs and then passes the result to the activation function. The activation function is a threshold function      that gives out 1 as the output if the sum of the weighted inputs is equal to or above the threshold value and 0 otherwise.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187c25a",
   "metadata": {},
   "source": [
    "Q.4) Explain the ADALINE network model.\n",
    "\n",
    "  :- ADALINE (Adaptive Linear Neuron or later Adaptive Linear Element) is an early single-layer artificial neural network and        the name of the physical device that implemented this network. The network uses memistors. Adaline is a single layer            neural network with multiple nodes where each node accepts multiple inputs and generates one output. A multilayer network      of ADALINE units is known as a MADALINE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086db277",
   "metadata": {},
   "source": [
    "Q.5) What is the constraint of a simple perceptron? Why it may fail with a real-world data set?\n",
    "\n",
    "  :- The output of a perceptron can only be a binary number (0 or 1) due to the hard limit transfer function. Perceptron can        only be used to classify the linearly separable sets of input vectors. If input vectors are non-linear, it is not easy to      classify them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5813e9",
   "metadata": {},
   "source": [
    "Q.6) What is linearly inseparable problem? What is the role of the hidden layer?\n",
    "\n",
    "  :- Clearly not all decision problems are linearly separable: they cannot be solved using a linear decision boundary. Problems      like these are termed linearly inseparable. XOR is a linearly inseparable problem. Hidden layer(s) are the secret sauce of      your network. They allow you to model complex data thanks to their nodes/neurons. They are “hidden” because the true            values of their nodes are unknown in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35a2d9",
   "metadata": {},
   "source": [
    "Q.7) Explain XOR problem in case of a simple perceptron.\n",
    "\n",
    "  :- The XOr problem is that we need to build a Neural Network (a perceptron in our case) to produce the truth table related to      the XOr logical operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3877fd",
   "metadata": {},
   "source": [
    "Q.8) Explain the single-layer feed forward architecture of ANN.\n",
    "\n",
    "  :- Feel forward network has 2 types single-layer feed forward & Multilayer feedforward network. The concept is of feedforward      ANN having only one weighted layer. In other words, we can say the input layer is fully connected to the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934fcf3",
   "metadata": {},
   "source": [
    "Q.9) Explain the competitive network architecture of ANN.\n",
    "\n",
    "  :- A neural network consists of three layers. The first layer is the input layer. It contains the input neurons that send          information to the hidden layer. The hidden layer performs the computations on input data and transfers the output to the      output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d131d5",
   "metadata": {},
   "source": [
    "Q.10) Consider a multi-layer feed forward neural network. Enumerate and explain steps in the backpropagation algorithm used to       train the network.\n",
    "\n",
    "   :- The backpropagation algorithm performs learning on a multilayer feed-forward neural network. It iteratively learns a set       of weights for prediction of the class label of tuples. A multilayer feed-forward neural network consists of an input           layer, one or more hidden layers, and an output layer.\n",
    "      Step – 1: Forward Propagation.\n",
    "      Step – 2: Backward Propagation.\n",
    "      Step – 3: Putting all the values together and calculating the updated weight value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b22aba",
   "metadata": {},
   "source": [
    "Q.11) What are the advantages and disadvantages of neural networks?\n",
    "\n",
    "   :- Advantages -\n",
    "      i) A neural network can implement tasks that a linear program cannot.\n",
    "\n",
    "      ii) When an item of the neural network declines, it can continue without some issues by its parallel features.\n",
    "\n",
    "      iii) A neural network determines and does not require to be reprogrammed.\n",
    "\n",
    "       iv) It can be executed in any application.\n",
    "       \n",
    "       Disadvantages - \n",
    "       i) The neural network required training to operate.\n",
    "\n",
    "       ii) The structure of a neural network is disparate from the structure of microprocessors therefore required to be                  emulated.\n",
    "\n",
    "       iii) It needed high processing time for big neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494b42b",
   "metadata": {},
   "source": [
    "Q.12) Write short notes on any two of the following:\n",
    "\n",
    "   i) Biological Neuron\n",
    "   :- In living organisms, the brain is the control unit of the neural network, and it has different subunits that take care of       vision, senses, movement, and hearing. The brain is connected with a dense network of nerves to the rest of the body’s         sensors and actors. There are approximately 10¹¹ neurons in the brain, and these are the building blocks of the complete       central nervous system of the living body. \n",
    "      The neuron is the fundamental building block of neural networks. In the biological systems, a neuron is a cell just like       any other cell of the body, which has a DNA code and is generated in the same way as the other cells. Though it might           have different DNA, the function is similar in all the organisms. A neuron comprises three major parts: the cell body          (also called Soma), the dendrites, and the axon. The dendrites are like fibers branched in different directions and are         connected to many cells in that cluster.\n",
    "      Dendrites receive the signals from surrounding neurons, and the axon transmits the signal to the other neurons. At the         ending terminal of the axon, the contact with the dendrite is made through a synapse. Axon is a long fiber that                 transports the output signal as electric impulses along its length. Each neuron has one axon. Axons pass impulses from         one neuron to another like a domino effect.\n",
    "      \n",
    "   ii) Recurrent networks\n",
    "    :- Recurrent Neural Network(RNN) is a type of Neural Network where the output from the previous step are fed as input to          the current step. In traditional neural networks, all the inputs and outputs are independent of each other, but in cases        like when it is required to predict the next word of a sentence, the previous words are required and hence there is a          need to remember the previous words. Thus RNN came into existence, which solved this issue with the help of a Hidden            Layer. The main and most important feature of RNN is Hidden state, which remembers some information about a sequence.\n",
    "       RNN have a “memory” which remembers all information about what has been calculated. It uses the same parameters for each        input as it performs the same task on all the inputs or hidden layers to produce the output. This reduces the complexity        of parameters, unlike other neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
